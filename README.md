# Project-4-Cost of Living


Group 2: Project 4 - Cost of Living Analysis

**Group Members:**
- Brittany Castro
- Cooper Harris
- Lois Stetson
- Thanh Vo

**Data Project Proposal: Cost of Living in the US**

**Introduction:**
The objective is to analyze the cost of living using a machine learning model. The project aims to develop and optimize a predictive model that estimates the cost of living based on various features. This assists in compensation planning for future employees, considering location factors.

**Data Source:**
[US Cost of Living Dataset](https://www.kaggle.com/datasets/asaniczka/us-cost-of-living-dataset-3171-counties?rvi=1)

**Problem Statement: Analyzing Cost of Living with Machine Learning**
The project focuses on leveraging machine learning for a comprehensive cost of living analysis. It involves data cleaning, normalization, and standardization processes. Utilizing data from Spark enhances data processing capabilities, aiming for meaningful predictive power. The goal is to optimize the model, document changes, and showcase overall performance, providing insights into cost of living dynamics.

**Project Overview:**

**Data Model Implementation:**
1. **Initialization, Training, and Evaluation:**
   - Develop a Python script using popular ML libraries like sklearn.
2. **Data Cleaning, Normalization, and Standardization:**
   - Implement processes to handle missing values and outliers.
   - Normalize and standardize features for consistent scaling.
3. **Utilization of Data from Spark:**
   - Incorporate data retrieval from Spark to enhance processing capabilities.
4. **Meaningful Predictive Power:**
   - Ensure the model achieves at least 75% classification accuracy or 0.80 R-squared.

**Data Model Optimization:**
1. **Optimization and Evaluation Documentation:**
   - Document the iterative model optimization process.
   - Record changes and impacts in a CSV/Excel table or within the Python script.
2. **Overall Model Performance Display:**
   - Print or display overall model performance.
   - Provide insights into effectiveness and areas for improvement.

**Proposed Timeline:**
- **Week 1:** Project Initialization
  - Review existing Jupyter notebook and understand the dataset.
  - Set up project structure and initialize version control.
- **Week 2:** Data Preparation and Cleaning
  - Implement data cleaning processes and handle outliers.
  - Normalize and standardize features.
- **Week 3:** Model Implementation
  - Develop Python script for initializing, training, and evaluating the model.
  - Incorporate data retrieval from Spark.
- **Week 4:** Model Optimization
  - Document model optimization process and changes.
  - Display overall model performance.
- **Week 5:** Finalization and Documentation
  - Perform final testing and validation.
  - Document the entire process with code comments and explanations.

**Expected Deliverables:**
1. Python script (`Cost_of_Living.py`) with the implemented model and data processing steps.
2. Documentation highlighting the model optimization process, including a CSV/Excel table or in-code comments.
3. Comprehensive README file explaining project structure, dependencies, and instructions for running the script.

**Team Members and Responsibilities:**
1. **Data Cleaning and Processing:**
   - Responsibilities: Implement data cleaning processes and feature engineering.
2. **Model Implementation:**
   - Responsibilities: Develop Python script for initializing, training, and evaluating the model.
3. **Data Retrieval and Integration:**
   - Responsibilities: Retrieve data from Spark and integrate it into the script.
4. **Model Optimization and Documentation:**
   - Responsibilities: Document the model optimization process and overall model performance.
   
**Conclusion:**
This project aims to create a robust machine learning model for cost of living analysis. The proposed timeline and responsibilities ensure a systematic approach to achieve the project objectives.
